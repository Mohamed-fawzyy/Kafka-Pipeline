# Project Scenario üé©
You are a data engineer at a data analytics consulting company. You have been assigned to a project that aims to de-congest the national highways by analyzing the road traffic data from different toll plazas. As a vehicle passes a toll plaza, the vehicle‚Äôs data like `vehicle_id`, `vehicle_type`, `toll_plaza_id`, and timestamp are streamed to Kafka. Your job is to create a data pipeline that collects the streaming data and loads it into a database.

# Objectivesüìù
* In this project you will create a streaming data pipe by performing these steps:

  * Start a MySQL Database server.
  * Create a table to hold the toll data.
  * Start the Kafka server.
  * Install the Kafka Python driver.
  * Install the MySQL Python driver.
  * Create a topic named toll in Kafka.
  * Download the streaming data generator program.
  * Customize the generator program to steam to toll topic.
  * Download and customize streaming data consumer.
  * Customize the consumer program to write into a MySQL database table.
  * Verify that streamed data is being collected in the database table.


# Reach/Follow me on üöÄ<br>
<p align="left">
  <a href="https://www.linkedin.com/in/mohamed-fawzy-936b661b8/" target="_blank" rel="noreferrer"> <img src="https://img.icons8.com/fluency/2x/linkedin.png" alt="linkedIn" width="50" height="50"/> </a>&nbsp&nbsp
  <a href="mailto:fwzymohamed90@gmail.com" target="_blank" rel="noreferrer"> <img src="https://img.icons8.com/fluency/2x/google-logo.png" alt="googleEmail" width="50" height="50"/> </a>&nbsp&nbsp
  <a href="https://www.facebook.com/mohamed.fwzy.14" target="_blank" rel="noreferrer"> <img src="https://cdn.iconscout.com/icon/free/png-256/facebook-262-721949.png" alt="facebook" width="50" height="50"/> </a>
</p>
<br>

# Prepare the lab environment üì¶
* Step 1: Download Kafka.
```bash
wget https://archive.apache.org/dist/kafka/2.8.0/kafka_2.12-2.8.0.tgz
```

* Step 2: Extract Kafka.
```bash
tar -xzf kafka_2.12-2.8.0.tgz
```

* Step 3: Start MySQL server.
```bash
start_mysql
```

* Step 4: Connect to the mysql server. Make sure you use the password given to you when the MySQL server starts.
```bash
mysql --host=127.0.0.1 --port=3306 --user=root --password=yourpassword
```

* Step 5: Create a database named `tolldata`.
At the ‚Äòmysql>‚Äô prompt, run the command below to create the database.
```bash
create database tolldata;
```

* Step 6: Create a table named `livetolldata` with the schema to store the data generated by the traffic simulator.
Run the following command to create the table:
```bash
use tolldata;

create table livetolldata(timestamp datetime,vehicle_id int,vehicle_type char(15),toll_plaza_id smallint);
```
<!-- Side Note: Additional Information -->
> Note: This is the table where you would store all the streamed data that comes from kafka. Each row is a record of when a vehicle has passed through a certain toll plaza along with its type and anonymized id.

* Step 7: Disconnect from MySQL server. 
```bash
exit
```

* Step 8: Install the python module `kafka-python` using the pip command.
```bash
python3 -m pip install kafka-python
```
<!-- Side Note: Additional Information -->
> Note: This python module will help you to communicate with kafka server. It can used to send and receive messages from kafka.


* Step 9: Install the python module `mysql-connector-python` using the pip command.
```bash
python3 -m pip install mysql-connector-python==8.0.31
```

# Directions üó∫
<b>Start Kafka with the following tasks</b>

1. Start Zookeeper
2. Start Kafka server
3. Create a topic named `toll`
4. Download the Toll Traffic Simulator
* Download the `toll_traffic_generator.py` from the url given below using ‚Äòwget‚Äô.
```bash
https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/toll_traffic_generator.py
```
<br>

5. Open the `toll_traffic_generator.p`y and set the topic to `toll`.
6. Task 2.6 - Run the Toll Traffic Simulator
- Run the `toll_traffic_generator.py`.
<!-- Side Note: Additional Information -->
> Hint : `python3 <pythonfilename>` runs a python program on your terminal.

<br>

7. Configure `streaming_data_reader.py`
- Download the `streaming_data_reader.py` from the url below using ‚Äòwget‚Äô.
```bash
https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0250EN-SkillsNetwork/labs/Final%20Assignment/streaming_data_reader.py
```
- Open the `streaming_data_reader.py` and modify the following details so that the program can connect to your mysql server.

`TOPIC`

`DATABASE`

`USERNAME`

`PASSWORD`

<br>

8. Run `streaming_data_reader.py`
```bash
python3 streaming_data_reader.py
```
9. Health check of the streaming data pipeline.
- If you have done all the steps till here correctly, the streaming toll data will get stored in the table `livetolldata`.
<!-- Side Note: Additional Information -->
> Try: List the top 10 rows in the table `livetolldata`.


# SnapShot and Results üì∏
* I provided my solution for this project a Bash file script go and check it out.
* After implementations your results of the Kafka pipeline should look like this:

  - <b>Simulator output of task 6</b>
    ![simulator_output](https://github.com/Mohamed-fawzyy/Kafka-Pipeline/assets/111665714/ba426df3-a5f5-4270-8628-cf15ac455e44)


  - <b> Stream reader to run python file. Output of task 7</b> <br>
    ![streaming_reader_code](https://github.com/Mohamed-fawzyy/Kafka-Pipeline/assets/111665714/fe691f71-18b2-4e0b-a46a-a196fc693361)


  - <b> Data reader to start workflow with Kafka. Output of task 8</b> <br>
  ![data_reader_output](https://github.com/Mohamed-fawzyy/Kafka-Pipeline/assets/111665714/6bb2269c-01b8-4821-a88f-05a671137b10)



  - <b> After running all previous commands correctly your final result should be like this. Output of task 9</b> <br>
    ![output_rows](https://github.com/Mohamed-fawzyy/Kafka-Pipeline/assets/111665714/ff3fbac2-9a49-4e96-886c-7e113e2321ac)


# Contributing üìù
Contributions are welcome! Please open an issue or pull request for any changes or improvements.




